# DataXMaskRecognition
This is a TensorFlow model (done on a Kaggle Notebook) for image classification that includes layers for convolution, pooling, and fully connected neural networks. It also includes data pre-processing steps like rescaling and data prefetching to optimize performance. The model is compiled with Adam optimizer, sparse categorical cross-entropy loss, and accuracy metrics. Additionally, early stopping callback is included to monitor validation loss and restore the best weights.
The model is designed to classify images into one of two classes ie 'withMask' and 'withoutMask'. It uses a sequential model architecture, where layers are stacked on top of each other in a linear fashion. The convolutional layers learn features from the input image and the pooling layers downsample the image by reducing its dimensions. The output of the convolutional and pooling layers is then flattened into a 1D tensor and passed through fully connected layers to make predictions. The final layer uses a sigmoid activation function to output a probability for each class.
The model is optimized for performance with data prefetching, which fetches data from storage to memory in advance of when it is needed, and data caching, which stores data in memory for quicker access during training. The Adam optimizer is used to minimize the loss function and the sparse categorical cross-entropy loss is used because there are only two classes. The model is trained with an early stopping callback, which monitors the validation loss and stops training when the loss stops improving after a certain number of epochs to prevent overfitting. 
After visualizing the accuracy of the model on the training and validation datasets, the next step was to evaluate the performance of the model on the test dataset. The test dataset provided an unbiased estimate of the model's performance on new, unseen data. To evaluate the accuracy of the model on the test dataset, the model.evaluate() method was used, which returned the test loss and test accuracy of the model. The test accuracy was printed to see how well the model was performing on the test data.
In addition to evaluating the model's accuracy on the test dataset, the confusion matrix for the test dataset was computed. The confusion matrix is a table that summarizes the performance of the model by comparing the predicted labels with the true labels. To compute the confusion matrix for the test dataset, the sklearn.metrics.confusion_matrix() method was used, which takes as input the true labels and the predicted labels, and returns a matrix that shows the number of true positives, false positives, true negatives, and false negatives for each class. The confusion matrix was then printed to see how well the model was performing for each class.
Finally, the confusion matrix for the validation dataset was also computed. The validation dataset provided an estimate of the model's performance during training and was useful for detecting overfitting. The images and labels were extracted from the validation dataset, predictions were made on the images using the model, and the confusion matrix for the validation dataset was computed using the sklearn.metrics.confusion_matrix() method. The confusion matrix was then printed to see how well the model was performing on the validation data. 
DataSource- https://www.kaggle.com/datasets/ashishjangra27/face-mask-12k-images-dataset
